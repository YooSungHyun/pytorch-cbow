``` json
[
  {
    "name": "dpo train",
    "type": "debugpy",
    "request": "launch",
    "module": "deepspeed.launcher.runner",
    "console": "integratedTerminal",
    "justMyCode": false,
    "subProcess": true,
    "env": {
        "OMP_NUM_THREADS": "16"
    },
    "cwd": "${workspaceFolder}/LLM42/train",
    "args": [
        "--include=localhost:0,1,2,3,4,5,6,7",
        "--master_port=61000",
        "./train_dpo.py",
        "--output_dir=./outputs/bart-test",
        "--max_length=2048",
        "--num_train_epochs=1",
        "--per_device_train_batch_size=16",
        "--learning_rate=5e-7",
        "--lr_scheduler_type=cosine",
        "--warmup_ratio=0.1",
        "--gradient_accumulation_steps=1",
        "--evaluation_strategy=no",
        "--save_strategy=epoch",
        "--logging_strategy=steps",
        "--logging_steps=1",
        "--save_total_limit=4",
        "--report_to=none",
        "--remove_unused_columns=False",
        "--gradient_checkpointing=True",
        "--torch_compile=True",
        "--bf16",
        "--tf32=True",
        "--deepspeed=./config/zero3_adafactor_30b_batch1_24GB.json"
    ]
  },
  {
    "name": "bart_test",
    "type": "python",
    "request": "launch",
    "program": "/data2/bart/temp_workspace/stt/tadev-STT/transformers_wav2vec2/run_speech_recognition_ctc.py",
    "cwd": "/data2/bart/temp_workspace/stt/tadev-STT/transformers_wav2vec2/scripts/finetune",
    "console": "integratedTerminal",
    "justMyCode": false,
    "subProcess": true,
    "env": {
        "WANDB_DISABLED": "true",
        "CUDA_VISIBLE_DEVICES": "0",
    },
    "args": [
        "--datasets_dirs=/data2/bart/temp_workspace/stt/aihub_datasets_arrow/fine-tuning/42maru/data-KsponSpeech-42maru-not-normal-20",
        "--ctc_linear_vocab_path=/data2/bart/temp_workspace/stt/aihub_datasets_arrow/fine-tuning/42maru/42maru_vocab/syllabel_vocab.json",
        "--model_name_or_path=/data2/bart/temp_workspace/stt/scratch_pretrain/checkpoint-200000",
        "--output_dir=./debug_outputs",
        "--overwrite_output_dir",
        "--max_steps=640000",
        "--save_total_limit=3",
        "--save_strategy=no",
        "--save_steps=1000",
        "--evaluation_strategy=no",
        "--eval_steps=1000",
        "--logging_steps=1",
        "--warmup_steps=0",
        "--learning_rate=0.0003",
        "--weight_decay=0",
        "--per_device_train_batch_size=2",
        "--gradient_accumulation_steps=2",
        "--per_device_eval_batch_size=2",
        "--seed=42",
        "--cache_dir=./.cache",
        "--adam_beta2=0.98",
        "--warmup_step_ratio=0.1",
        "--hold_step_ratio=0.4",
        "--decay_step_ratio=0.5",
        "--init_learning_rate=0.035",
        "--final_learning_rate=0.05",
        "--metric_for_best_model=eval_wer",
        "--group_by_length",
        "--load_best_model_at_end",
        "--do_train=true",
        "--do_eval=false",
    ]
  },
  {
      "name": "joint_training",
      "type": "python",
      "request": "launch",
      "module": "torch.distributed.launch",
      "cwd": "${workspaceFolder}/temp_workspace/stt/tadev-STT",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": true,
      "env": {
          "WANDB_DISABLED": "true",
          "CUDA_VISIBLE_DEVICES": "0,1,2,3",
          "OMP_NUM_THREADS": "16"
      },
      "args": [
          "--nproc_per_node=4",
          "${workspaceFolder}/temp_workspace/stt/tadev-STT/transformers-wav2vec2/run_speech_recognition_joint.py",
          "--datasets_dir=/home/bart/temp_workspace/stt/wav2vec2_test/aihub_datasets_arrow/fine-tuning/new-data-KsponSpeech-spelling-not-normal-20",
          "--model_name_or_path=/home/bart/temp_workspace/stt/scratch_pretrain/checkpoint-200000/",
          "--output_dir=/home/bart/temp_workspace/stt/output_dir/grapheme",
          "--overwrite_output_dir",
          "--max_steps=640000",
          "--save_total_limit=3",
          "--save_strategy=steps",
          "--save_steps=1000",
          "--evaluation_strategy=steps",
          "--eval_steps=1000",
          "--logging_steps=1",
          "--warmup_steps=0",
          "--learning_rate=0.0002",
          "--weight_decay=0",
          "--per_device_train_batch_size=2",
          "--gradient_accumulation_steps=2",
          "--per_device_eval_batch_size=2",
          "--seed=42",
          "--cache_dir=./.cache",
          "--warmup_step_ratio=0.3",
          "--hold_step_ratio=0.2",
          "--decay_step_ratio=0.5",
          "--init_learning_rate=0.05",
          "--final_learning_rate=0.05",
          "--model_config_path=/home/bart/temp_workspace/stt/scratch_pretrain/checkpoint-200000/bart_config.json",
          "--group_by_length",
          "--fp16",
          "--metric_for_best_model=eval_wer",
          "--load_best_model_at_end",
          "--do_train=false",
          "--do_eval",
          "--use_ctc_linear",
          "--use_transformer=false",
          "--setproctitle_name=bart",
          "--wandb_project=[GPU03] Wav2Vec2ForCTC",
          "--wandb_entity=bart_tadev",
          "--wandb_name=Clean+Bart Best config(CTC)",
          "--ctc_linear_vocab_path=/home/bart/temp_workspace/stt/output_dir/grapheme/vocab.json",
          "--transformer_vocab_path=/home/bart/temp_workspace/stt/output_dir/syllabel/vocab.json",
          "--greater_is_better=false",
          "--do_normalize",
          "--label_names=ctc_linear_labels"
      ]
  }
]
```
